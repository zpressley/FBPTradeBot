#!/usr/bin/env python3
"""
FBP Data Pipeline Comprehensive Audit
Maps all data sources, pipelines, outputs, and consumers
Based on actual FBP project structure
"""

import json
import os
import pandas as pd
from datetime import datetime
from pathlib import Path
from collections import defaultdict

def format_size(bytes):
    """Format file size"""
    for unit in ['B', 'KB', 'MB']:
        if bytes < 1024.0:
            return f"{bytes:>6.1f} {unit}"
        bytes /= 1024.0
    return f"{bytes:>6.1f} GB"

def get_file_info(filepath):
    """Get comprehensive file info"""
    if not os.path.exists(filepath):
        return None
    
    stat = os.stat(filepath)
    mod_time = datetime.fromtimestamp(stat.st_mtime)
    age = datetime.now() - mod_time
    
    # Format age
    if age.days == 0:
        age_str = "Today"
    elif age.days == 1:
        age_str = "Yesterday"
    elif age.days < 7:
        age_str = f"{age.days}d ago"
    elif age.days < 30:
        age_str = f"{age.days//7}w ago"
    else:
        age_str = mod_time.strftime("%Y-%m-%d")
    
    # Count records
    records = "?"
    try:
        if filepath.endswith('.json'):
            with open(filepath, 'r') as f:
                data = json.load(f)
            if isinstance(data, list):
                records = len(data)
            elif isinstance(data, dict):
                if all(isinstance(v, list) for v in data.values()):
                    records = sum(len(v) for v in data.values())
                else:
                    records = len(data)
        elif filepath.endswith('.csv'):
            df = pd.read_csv(filepath)
            records = len(df)
    except:
        pass
    
    return {
        'size': format_size(stat.st_size),
        'modified': age_str,
        'records': records
    }

def print_section(title, emoji="üìã"):
    """Print section header"""
    print()
    print("=" * 100)
    print(f"{emoji} {title}")
    print("=" * 100)

def print_file_status(name, info, description="", indent="   "):
    """Print file status line"""
    if info:
        print(f"{indent}‚úÖ {name:<40} {info['size']} ‚îÇ {info['records']:>6} records ‚îÇ {info['modified']:>12} ‚îÇ {description}")
    else:
        print(f"{indent}‚ùå {name:<40} {'NOT FOUND':>10} ‚îÇ {description}")

def main():
    print()
    print("=" * 100)
    print("üéØ FBP DATA PIPELINE COMPREHENSIVE AUDIT")
    print("=" * 100)
    print(f"üìç Working directory: {os.getcwd()}")
    print(f"üïê Audit time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ============================================================================
    # SECTION 1: DATA SOURCES (External APIs & Sheets)
    # ============================================================================
    print_section("DATA SOURCES (External)", "üì•")
    
    print("\n   üåê Yahoo Fantasy API:")
    print("      ‚îî‚îÄ Provides: Active rosters, standings, matchups, player stats")
    print("      ‚îî‚îÄ Update: Daily during season, frozen in offseason")
    print("      ‚îî‚îÄ Auth: token.json (OAuth2)")
    
    print("\n   üìä Google Sheets (FBP HUB 2.0):")
    print("      ‚îî‚îÄ Sheet ID: 13oEFhmmVF82qMnX0NV_W0szmfGjZySNaOALg3MhoRzA")
    print("      ‚îî‚îÄ Provides: Prospect contracts, WizBucks, keeper contracts")
    print("      ‚îî‚îÄ Update: Manual by managers + bot updates")
    print("      ‚îî‚îÄ Auth: google_creds.json (Service Account)")
    
    print("\n   üìä Google Sheets (UPID Database):")
    print("      ‚îî‚îÄ Sheet ID: 19hH-bUVbtbF4Qn4Ep6YRCK853eOvoI8lr2zNlRB1wgo")
    print("      ‚îî‚îÄ Provides: 6,018 player UPIDs with alternate names")
    print("      ‚îî‚îÄ Update: Maintained externally")
    
    print("\n   ‚öæ MLB Stats API:")
    print("      ‚îî‚îÄ Provides: Player bio, service time, roster status, MiLB stats")
    print("      ‚îî‚îÄ Update: Real-time (rate limited)")
    print("      ‚îî‚îÄ Auth: None required (public API)")
    
    print("\n   üìà MLB Prospect Stats (Manual CSVs):")
    print("      ‚îî‚îÄ Files: mlb_prospect_batstats_2025.csv, mlb_prospect_pitchstats_2025.csv")
    print("      ‚îî‚îÄ Provides: 795 prospects with comprehensive stats")
    print("      ‚îî‚îÄ Update: Manual upload from MLB.com")
    
    # ============================================================================
    # SECTION 2: CORE DATA FILES
    # ============================================================================
    print_section("CORE DATA FILES", "üíæ")
    
    core_files = {
        "combined_players.json": "Master player database (ALL players - MLB + Farm)",
        "yahoo_players.json": "Current Yahoo rosters (12 teams)",
        "sheet_players.json": "Google Sheets player data",
        "mlb_id_cache.json": "UPID ‚Üí MLB ID mappings (2,745 entries)",
        "enhanced_mlb_id_cache.json": "Extended ID cache with BBRef IDs"
    }
    
    for filename, desc in core_files.items():
        filepath = f"data/{filename}"
        info = get_file_info(filepath)
        print_file_status(filename, info, desc)
    
    # ============================================================================
    # SECTION 3: STATISTICS & ANALYTICS
    # ============================================================================
    print_section("STATISTICS & ANALYTICS", "üìä")
    
    stats_files = {
        "fbp_prospect_stats_2025.csv": "Merged prospect stats (batters + pitchers)",
        "fbp_complete_stats.csv": "Complete stats (MLB advanced + MiLB)",
        "fbp_mlb_advanced.csv": "Fangraphs advanced stats (wOBA, wRC+, FIP, etc.)",
        "fbp_milb_stats.csv": "Minor league stats (all levels)",
        "service_stats.json": "Prospect service time tracking data",
        "flagged_for_review.json": "Prospects flagged for graduation"
    }
    
    for filename, desc in stats_files.items():
        filepath = f"data/{filename}"
        info = get_file_info(filepath)
        print_file_status(filename, info, desc)
    
    # ============================================================================
    # SECTION 4: FINANCIAL SYSTEM
    # ============================================================================
    print_section("FINANCIAL SYSTEM (WizBucks)", "üí∞")
    
    financial_files = {
        "wizbucks.json": "Current WizBucks balances (12 teams)",
        "wizbucks_installments.json": "PAD/KAP/APA period tracking",
        "wizbuck_transactions.json": "All WB transaction history"
    }
    
    for filename, desc in financial_files.items():
        filepath = f"data/{filename}"
        info = get_file_info(filepath)
        print_file_status(filename, info, desc)
    
    # ============================================================================
    # SECTION 5: COMPETITION & STANDINGS
    # ============================================================================
    print_section("COMPETITION & STANDINGS", "üèÜ")
    
    competition_files = {
        "standings.json": "Current standings + weekly matchups"
    }
    
    for filename, desc in competition_files.items():
        filepath = f"data/{filename}"
        info = get_file_info(filepath)
        print_file_status(filename, info, desc)
    
    # ============================================================================
    # SECTION 6: SERVICE TIME TRACKING
    # ============================================================================
    print_section("SERVICE TIME TRACKING", "‚è±Ô∏è")
    
    service_files = {
        "roster_events.json": "Call-up/send-down event log",
        "service_stats.json": "Current service time calculations",
        "flagged_for_review.json": "Prospects approaching limits"
    }
    
    for filename, desc in service_files.items():
        filepath = f"data/{filename}"
        info = get_file_info(filepath)
        print_file_status(filename, info, desc)
    
    # Check snapshots
    snapshot_dir = Path("data/roster_snapshots")
    if snapshot_dir.exists():
        snapshots = sorted(list(snapshot_dir.glob("*.json")))
        print(f"\n   üì∏ roster_snapshots/:")
        print(f"      ‚îî‚îÄ {len(snapshots)} daily snapshots")
        if snapshots:
            print(f"      ‚îî‚îÄ Latest: {snapshots[-1].name}")
            print(f"      ‚îî‚îÄ Oldest: {snapshots[0].name}")
    else:
        print(f"\n   ‚ùå roster_snapshots/ directory not created yet")
    
    # ============================================================================
    # SECTION 7: FUTURE/PLANNED FILES
    # ============================================================================
    print_section("FUTURE DATA FILES (Not Yet Implemented)", "üîÆ")
    
    future_files = {
        "keeper_salaries.json": "Keeper contract salary calculations",
        "draft_tax.json": "Draft pick penalties by team",
        "il_tags.json": "IL tag assignments for keeper deadline",
        "draft_picks.json": "Draft pick ownership tracker",
        "draft_boards.json": "Personal draft boards (12 teams)",
        "auction_current.json": "Active weekly auction bids",
        "auction_history.json": "Historical auction results",
        "transactions.json": "Master transaction ledger",
        "player_photos.json": "Player photo URLs with credits",
        "26man_compliance.json": "30-man roster compliance tracker"
    }
    
    for filename, desc in future_files.items():
        filepath = f"data/{filename}"
        info = get_file_info(filepath)
        print_file_status(filename, info, desc)
    
    # ============================================================================
    # SECTION 8: DATA PIPELINE SCRIPTS
    # ============================================================================
    print_section("DATA PIPELINE SCRIPTS", "‚öôÔ∏è")
    
    print("\n   üìÇ data_pipeline/ folder:")
    pipeline_scripts = {
        "update_all.py": "Master orchestrator (runs all updates)",
        "update_yahoo_players.py": "Fetch rosters from Yahoo API",
        "update_hub_players.py": "Fetch data from Google Sheets",
        "update_wizbucks.py": "Fetch WizBucks balances",
        "merge_players.py": "Merge Yahoo + Sheets ‚Üí combined_players.json",
        "save_standings.py": "Fetch and save standings + matchups"
    }
    
    for script, desc in pipeline_scripts.items():
        filepath = f"data_pipeline/{script}"
        if os.path.exists(filepath):
            print(f"      ‚úÖ {script:<30} {desc}")
        else:
            print(f"      ‚ùå {script:<30} {desc}")
    
    print("\n   üìÇ Root level scripts:")
    root_scripts = {
        "build_mlb_id_cache.py": "Build UPID ‚Üí MLB ID mappings",
        "track_roster_status.py": "Daily roster status snapshots",
        "log_roster_events.py": "Log call-ups/send-downs",
        "count_service_days.py": "Calculate service days from events"
    }
    
    for script, desc in root_scripts.items():
        if os.path.exists(script):
            print(f"      ‚úÖ {script:<30} {desc}")
        else:
            print(f"      ‚ùå {script:<30} {desc}")
    
    print("\n   üìÇ service_time/ folder:")
    service_scripts = {
        "flagged_service_tracker.py": "Track prospects approaching limits",
        "progress_bar_sheets.py": "Update Google Sheets with progress bars"
    }
    
    for script, desc in service_scripts.items():
        filepath = f"service_time/{script}"
        if os.path.exists(filepath):
            print(f"      ‚úÖ {script:<30} {desc}")
        else:
            print(f"      ‚ùå {script:<30} {desc}")
    
    # ============================================================================
    # SECTION 9: DATA FLOW DIAGRAM
    # ============================================================================
    print_section("DATA FLOW DIAGRAM", "üîÑ")
    
    print("""
   üì• DAILY INPUTS (Automated via GitHub Actions)
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Yahoo API          ‚Üí update_yahoo_players.py                 ‚îÇ
   ‚îÇ Google Sheets      ‚Üí update_hub_players.py                   ‚îÇ
   ‚îÇ Google Sheets (WB) ‚Üí update_wizbucks.py                      ‚îÇ
   ‚îÇ MLB Stats API      ‚Üí track_roster_status.py                  ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚Üì
   ‚öôÔ∏è  PROCESSING
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ merge_players.py   ‚Üí Combines Yahoo + Sheets                ‚îÇ
   ‚îÇ save_standings.py  ‚Üí Parses Yahoo standings XML              ‚îÇ
   ‚îÇ log_roster_events.py ‚Üí Detects call-ups/send-downs          ‚îÇ
   ‚îÇ build_mlb_id_cache.py ‚Üí UPID ‚Üí MLB ID mappings              ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚Üì
   üíæ CORE DATA FILES
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ combined_players.json    (2,504 players - MLB + Farm)       ‚îÇ
   ‚îÇ mlb_id_cache.json        (2,745 MLB IDs)                    ‚îÇ
   ‚îÇ standings.json           (12 teams + matchups)              ‚îÇ
   ‚îÇ wizbucks.json            (12 team balances)                 ‚îÇ
   ‚îÇ roster_events.json       (call-up/send-down history)        ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚Üì
   üì§ CONSUMERS
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Discord Bot (bot.py)                                         ‚îÇ
   ‚îÇ ‚îú‚îÄ /player   ‚Üí combined_players.json                        ‚îÇ
   ‚îÇ ‚îú‚îÄ /roster   ‚Üí combined_players.json                        ‚îÇ
   ‚îÇ ‚îú‚îÄ /trade    ‚Üí combined_players.json + wizbucks.json        ‚îÇ
   ‚îÇ ‚îî‚îÄ /standings ‚Üí standings.json                              ‚îÇ
   ‚îÇ                                                              ‚îÇ
   ‚îÇ FBP Hub Website (future)                                     ‚îÇ
   ‚îÇ ‚îú‚îÄ Player DB ‚Üí combined_players.json + prospect_stats       ‚îÇ
   ‚îÇ ‚îú‚îÄ Rosters   ‚Üí combined_players.json                        ‚îÇ
   ‚îÇ ‚îú‚îÄ WizBucks  ‚Üí wizbucks.json                                ‚îÇ
   ‚îÇ ‚îú‚îÄ Service   ‚Üí service_stats.json + flagged_for_review.json ‚îÇ
   ‚îÇ ‚îî‚îÄ Standings ‚Üí standings.json                               ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    """)
    
    # ============================================================================
    # SECTION 10: UPDATE FREQUENCY
    # ============================================================================
    print_section("UPDATE SCHEDULE", "üìÖ")
    
    schedules = {
        "üî¥ REAL-TIME (In-Season)": [
            ("Yahoo rosters", "Every waiver clear + manual refresh"),
            ("Standings/Matchups", "After each game day"),
            ("Player stats", "Live via MLB API")
        ],
        "üü† DAILY (Automated)": [
            ("combined_players.json", "6:00 AM EST via GitHub Actions"),
            ("yahoo_players.json", "6:00 AM EST"),
            ("sheet_players.json", "6:00 AM EST"),
            ("standings.json", "6:00 AM EST"),
            ("roster_snapshots/", "6:00 AM EST"),
            ("roster_events.json", "6:00 AM EST after snapshots")
        ],
        "üü° WEEKLY": [
            ("mlb_id_cache.json", "Rebuild for new prospects"),
            ("service_stats.json", "Service time calculations"),
            ("fbp_prospect_stats", "Update from MLB CSVs or API")
        ],
        "üü¢ SEASONAL": [
            ("PAD (Feb 10)", "Prospect assignments, DC/PC/BC contracts"),
            ("PPD (Feb 17)", "Prospect draft results"),
            ("KAP (Feb 20-28)", "Keeper assignments, IL tags, RaT"),
            ("Keeper Draft (Mar 8)", "Draft results, new contracts"),
            ("APA (Post-draft)", "Auction portal allotments"),
            ("Trade Deadline (Jul 31)", "TDA allotment distribution")
        ],
        "üîµ MANUAL": [
            ("MLB prospect CSVs", "Upload when available from MLB.com"),
            ("player_photos.json", "Manager uploads + admin approval"),
            ("WizBucks adjustments", "Commissioner manual corrections")
        ]
    }
    
    for category, items in schedules.items():
        print(f"\n   {category}:")
        for item, desc in items:
            print(f"      ‚Ä¢ {item:<30} {desc}")
    
    # ============================================================================
    # SECTION 11: ACTUAL FILE STATUS
    # ============================================================================
    print_section("ACTUAL FILE STATUS", "üìÇ")
    
    data_dir = Path("data")
    
    if not data_dir.exists():
        print("\n   ‚ùå data/ directory does not exist!")
        print("   üí° Create with: mkdir -p data")
        print("   üí° Then run: python3 data_pipeline/update_all.py")
        return
    
    print(f"\n   üìÅ Data directory: {data_dir.absolute()}")
    
    all_files = list(data_dir.glob("**/*"))
    data_files = [f for f in all_files if f.is_file() and not f.name.startswith('.')]
    
    print(f"   üìä Total files: {len(data_files)}")
    print(f"   üíæ Total size: {format_size(sum(f.stat().st_size for f in data_files))}")
    
    # Group by category
    print("\n   üìã Files by category:")
    
    json_files = [f for f in data_files if f.suffix == '.json' and 'snapshot' not in str(f)]
    csv_files = [f for f in data_files if f.suffix == '.csv']
    snapshot_files = [f for f in data_files if 'snapshot' in str(f)]
    
    print(f"\n      JSON files: {len(json_files)}")
    for f in sorted(json_files)[:10]:
        info = get_file_info(str(f))
        print(f"         ‚Ä¢ {f.name:<40} {info['size']} ‚îÇ {info['modified']}")
    
    if len(json_files) > 10:
        print(f"         ... and {len(json_files) - 10} more")
    
    print(f"\n      CSV files: {len(csv_files)}")
    for f in sorted(csv_files):
        info = get_file_info(str(f))
        print(f"         ‚Ä¢ {f.name:<40} {info['size']} ‚îÇ {info['modified']}")
    
    print(f"\n      Snapshot files: {len(snapshot_files)}")
    if snapshot_files:
        latest = max(snapshot_files, key=lambda f: f.stat().st_mtime)
        oldest = min(snapshot_files, key=lambda f: f.stat().st_mtime)
        print(f"         Latest: {latest.name}")
        print(f"         Oldest: {oldest.name}")
    
    # ============================================================================
    # SECTION 12: DATA QUALITY CHECKS
    # ============================================================================
    print_section("DATA QUALITY ANALYSIS", "üî¨")
    
    combined_file = "data/combined_players.json"
    if os.path.exists(combined_file):
        with open(combined_file, 'r') as f:
            combined = json.load(f)
        
        total = len(combined)
        mlb = sum(1 for p in combined if p.get('player_type') == 'MLB')
        farm = sum(1 for p in combined if p.get('player_type') == 'Farm')
        with_yahoo = sum(1 for p in combined if p.get('yahoo_id'))
        with_upid = sum(1 for p in combined if p.get('upid'))
        with_manager = sum(1 for p in combined if p.get('manager'))
        unowned = sum(1 for p in combined if not p.get('manager'))
        
        print(f"\n   üìä combined_players.json Quality:")
        print(f"      Total players: {total:,}")
        print(f"      ‚îú‚îÄ MLB players: {mlb:,}")
        print(f"      ‚îú‚îÄ Farm players: {farm:,}")
        print(f"      ‚îú‚îÄ With Yahoo ID: {with_yahoo:,}")
        print(f"      ‚îú‚îÄ With UPID: {with_upid:,}")
        print(f"      ‚îú‚îÄ Owned (has manager): {with_manager:,}")
        print(f"      ‚îî‚îÄ Unowned (available): {unowned:,}")
        
        # Check MLB ID cache coverage
        cache_file = "data/mlb_id_cache.json"
        if os.path.exists(cache_file):
            with open(cache_file, 'r') as f:
                cache = json.load(f)
            
            farm_in_cache = sum(1 for p in combined 
                               if p.get('player_type') == 'Farm' 
                               and str(p.get('upid')) in cache)
            
            coverage_pct = (farm_in_cache / farm * 100) if farm > 0 else 0
            
            print(f"\n   üîó MLB ID Cache Coverage:")
            print(f"      Total cache entries: {len(cache):,}")
            print(f"      Farm players covered: {farm_in_cache:,}/{farm:,} ({coverage_pct:.1f}%)")
            print(f"      Missing MLB IDs: {farm - farm_in_cache:,}")
    
    # Check prospect stats
    prospect_stats = "data/fbp_prospect_stats_2025.csv"
    if os.path.exists(prospect_stats):
        df = pd.read_csv(prospect_stats)
        
        batters = len(df[df['player_type'] == 'batter'])
        pitchers = len(df[df['player_type'] == 'pitcher'])
        
        print(f"\n   üìà Prospect Stats Coverage:")
        print(f"      Total with stats: {len(df):,}")
        print(f"      ‚îú‚îÄ Batters: {batters:,}")
        print(f"      ‚îî‚îÄ Pitchers: {pitchers:,}")
        
        # Show available stat columns
        stat_cols = [c for c in df.columns if c not in ['upid', 'name', 'player_type', 'manager']]
        print(f"      Stats available: {len(stat_cols)} columns")
        print(f"         Sample: {', '.join(stat_cols[:8])}")
    
    # ============================================================================
    # SECTION 13: DISCORD BOT STATUS
    # ============================================================================
    print_section("DISCORD BOT INTEGRATION", "ü§ñ")
    
    bot_commands = {
        "/player": {
            "files": ["combined_players.json"],
            "desc": "Lookup any player across all teams"
        },
        "/roster": {
            "files": ["combined_players.json"],
            "desc": "View team rosters (MLB + Farm)"
        },
        "/trade": {
            "files": ["combined_players.json", "wizbucks.json"],
            "desc": "Submit trade proposals"
        },
        "/standings": {
            "files": ["standings.json"],
            "desc": "Current standings + matchups"
        }
    }
    
    print("\n   Discord Commands ‚Üí Data Dependencies:")
    for cmd, info in bot_commands.items():
        file_list = info["files"]
        desc = info["desc"]
        all_exist = all(os.path.exists(f"data/{f}") for f in file_list)
        status = "‚úÖ" if all_exist else "‚ùå"
        print(f"      {status} {cmd:<15} {desc}")
        for f in file_list:
            exists = "‚úÖ" if os.path.exists(f"data/{f}") else "‚ùå"
            print(f"         {exists} Needs: {f}")
    
    # ============================================================================
    # SECTION 14: RECOMMENDATIONS
    # ============================================================================
    print_section("RECOMMENDATIONS & NEXT STEPS", "üéØ")
    
    # Check what's missing
    critical_missing = []
    if not os.path.exists("data/combined_players.json"):
        critical_missing.append("combined_players.json")
    if not os.path.exists("data/mlb_id_cache.json"):
        critical_missing.append("mlb_id_cache.json")
    
    if critical_missing:
        print("\n   üö® CRITICAL - Discord bot won't work without these:")
        for f in critical_missing:
            print(f"      ‚ùå {f}")
        print("\n   üîß Quick fix:")
        print("      cd ~/fbp-trade-bot")
        print("      python3 data_pipeline/update_all.py")
    else:
        print("\n   ‚úÖ CORE DATA FILES PRESENT - Bot should work!")
    
    print("\n   üìÖ DAILY AUTOMATION:")
    print("      ‚úÖ GitHub Actions workflow exists")
    print("      ‚îî‚îÄ Runs: update_all.py at 6:00 AM EST daily")
    print("      ‚îî‚îÄ Updates: combined_players.json, standings.json, wizbucks.json")
    
    print("\n   üîÑ MANUAL TASKS:")
    print("      ‚Ä¢ Upload MLB prospect CSVs weekly (for better stats)")
    print("      ‚Ä¢ Run merge_with_upid_alternates.py after CSV upload")
    print("      ‚Ä¢ Run service time tracker for graduation flags")
    
    print("\n   üöÄ FOR WEBSITE DEVELOPMENT:")
    print("      Priority files to expose:")
    print("      1. combined_players.json - Player database with search")
    print("      2. fbp_prospect_stats_2025.csv - Prospect stats + rankings")
    print("      3. wizbucks.json - WizBucks balances")
    print("      4. standings.json - Current standings")
    print("      5. service_stats.json - Service time progress bars")
    
    # ============================================================================
    # FINAL SUMMARY
    # ============================================================================
    print()
    print("=" * 100)
    print("üìä PIPELINE HEALTH SUMMARY")
    print("=" * 100)
    
    health_score = 0
    max_score = 5
    
    if os.path.exists("data/combined_players.json"):
        print("   ‚úÖ Core player database")
        health_score += 1
    else:
        print("   ‚ùå Core player database missing")
    
    if os.path.exists("data/mlb_id_cache.json"):
        print("   ‚úÖ MLB ID mappings")
        health_score += 1
    else:
        print("   ‚ùå MLB ID mappings missing")
    
    if os.path.exists("data/standings.json"):
        print("   ‚úÖ Standings data")
        health_score += 1
    else:
        print("   ‚ùå Standings data missing")
    
    if os.path.exists("data/wizbucks.json"):
        print("   ‚úÖ WizBucks data")
        health_score += 1
    else:
        print("   ‚ùå WizBucks data missing")
    
    if os.path.exists("data_pipeline/update_all.py"):
        print("   ‚úÖ Automated pipeline")
        health_score += 1
    else:
        print("   ‚ùå Automated pipeline missing")
    
    health_pct = (health_score / max_score) * 100
    
    print(f"\n   Pipeline Health: {health_score}/{max_score} ({health_pct:.0f}%)")
    
    if health_score == max_score:
        print("   üéâ All systems operational!")
    elif health_score >= 3:
        print("   ‚ö†Ô∏è Core systems working, some enhancements needed")
    else:
        print("   üö® Critical systems missing, run data pipeline setup")
    
    print()
    print("=" * 100)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\n‚ùå Audit failed: {e}")
        import traceback
        traceback.print_exc()